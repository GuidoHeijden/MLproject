{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-8ahxku28Pvt"
   },
   "source": [
    "## Importing necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gVNzBSHLryUt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFoEQm8jsND4"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive\n",
    " \n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    " \n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 89118,
     "status": "ok",
     "timestamp": 1544710447758,
     "user": {
      "displayName": "Guido van der Heijden",
      "photoUrl": "https://lh3.googleusercontent.com/-Pgcdi2UCksE/AAAAAAAAAAI/AAAAAAAAABE/U-831Kz0YeQ/s64/photo.jpg",
      "userId": "00325871125681610562"
     },
     "user_tz": -60
    },
    "id": "6YoEuhmgui1W",
    "outputId": "f5a8a495-6b34-41af-f6b1-dafa3dc26f48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: Proposal, id: 1ptu0wHv8T1j-q43l6tnDSbyhlpcRzy_1\n",
      "title: Notebooks, id: 1SIEKxEEUHWNiRsw8oBo5IeSIYP28lpHF\n",
      "title: own_data, id: 1GZWg9525HDk_w3HUb_7kk4nUhQ5uICi7\n",
      "title: submissions, id: 1--lgm6fsx-MHBTsJZRQOjngQlsftVgrb\n",
      "title: all, id: 1nfuIpYtfv57Nc9yHi3d1HPXCzIi4q8aF\n",
      "\n",
      "title: Notebook Project - training and testing.ipynb, id: 1AMr18Ner4pxbiSToTdBhX22e1a9x9WqL\n",
      "title: Notebook Project - extra features.ipynb, id: 1cbkKXCbuc7B3jeIRfZYx_yYG2V3p4ekG\n",
      "\n",
      "title: train_without_outliers.csv, id: 15RcBCIFHwkOoiPWRnlRA7UEjesUVkusA\n",
      "title: train_extra_features.csv, id: 1pONcYfZ5NHfOROn1rpNFrx7_0Jdn_Mf9\n",
      "title: test_extra_features.csv, id: 17AoSBa0GsW0LSS-obXmBSmtOK3GodlJI\n",
      "\n",
      "title: submission_v0-003.csv, id: 1hvHA9UOGk15IHhre-yrYLp6JqnCHMmt4\n",
      "title: submission_v0-002.csv, id: 1xk3AEFkTZZZXuerG3Nn9IilgvntmA0gb\n",
      "title: submission_v0-001.csv, id: 16YtBcPoqNGaMYhPyTuAdD4k_Lj9sDWY5\n",
      "\n",
      "title: train.csv, id: 1H5CmpWJK0muRjFda-UqvzGUmo8vlWrCA\n",
      "title: test.csv, id: 1so_6lvzm8a1lDNq7t74pLfk7F3EYVr1R\n",
      "title: sample_submission.csv, id: 1NhBwCTwuARMBYX42IkpJxkLVxna8izrO\n",
      "title: new_merchant_transactions.csv, id: 1j6h1qYKDITa7sLKbBIQqb63zCPEPZ1UY\n",
      "title: merchants.csv, id: 1PBJFVu_xFxIPRh1cEw3x2fQf_xN-S3c0\n",
      "title: historical_transactions.csv, id: 1FnqGiInHD6iCUAV_252NKriQysR4CNix\n",
      "title: Data_Dictionary.xlsx, id: 1_iodVkb84yU7ypEk26Xzld7mUDBCht7m\n"
     ]
    }
   ],
   "source": [
    "# Loading all the files in the drive\n",
    "\n",
    "file_list1 = drive.ListFile({'q': \"'1OW2PfnLSteLhfwn6k4gscnah3TLLiVJh' in parents and trashed=false\"}).GetList()\n",
    "for file1 in file_list1:\n",
    "  print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
    "\n",
    "print()\n",
    "  \n",
    "file_list2 = drive.ListFile({'q': \"'1SIEKxEEUHWNiRsw8oBo5IeSIYP28lpHF' in parents and trashed=false\"}).GetList()\n",
    "for file1 in file_list2:\n",
    "  print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
    "\n",
    "print()\n",
    "  \n",
    "file_list3 = drive.ListFile({'q': \"'1GZWg9525HDk_w3HUb_7kk4nUhQ5uICi7' in parents and trashed=false\"}).GetList()\n",
    "for file1 in file_list3:\n",
    "  print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
    "  \n",
    "print()\n",
    "  \n",
    "file_list4 = drive.ListFile({'q': \"'1--lgm6fsx-MHBTsJZRQOjngQlsftVgrb' in parents and trashed=false\"}).GetList()\n",
    "for file1 in file_list4:\n",
    "  print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
    "\n",
    "print()\n",
    "  \n",
    "file_list5 = drive.ListFile({'q': \"'1nfuIpYtfv57Nc9yHi3d1HPXCzIi4q8aF' in parents and trashed=false\"}).GetList()\n",
    "for file1 in file_list5:\n",
    "  print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
    "\n",
    "training_and_testing = drive.CreateFile({'id': '1AMr18Ner4pxbiSToTdBhX22e1a9x9WqL'})\n",
    "training_and_testing.GetContentFile('training and testing.ipynb')\n",
    "extra_features = drive.CreateFile({'id': '1cbkKXCbuc7B3jeIRfZYx_yYG2V3p4ekG'})\n",
    "extra_features.GetContentFile('extra features.ipynb')\n",
    "  \n",
    "train_without_outliers = drive.CreateFile({'id': '15RcBCIFHwkOoiPWRnlRA7UEjesUVkusA'})\n",
    "train_without_outliers.GetContentFile('train_without_outliers.csv')\n",
    "train_extra_features = drive.CreateFile({'id': '1pONcYfZ5NHfOROn1rpNFrx7_0Jdn_Mf9'})\n",
    "train_extra_features.GetContentFile('train_extra_features.csv')\n",
    "test_extra_features = drive.CreateFile({'id': '17AoSBa0GsW0LSS-obXmBSmtOK3GodlJI'})\n",
    "test_extra_features.GetContentFile('test_extra_features.csv')\n",
    "\n",
    "train_down = drive.CreateFile({'id': '1H5CmpWJK0muRjFda-UqvzGUmo8vlWrCA'})\n",
    "train_down.GetContentFile('train.csv')\n",
    "test_down = drive.CreateFile({'id': '1so_6lvzm8a1lDNq7t74pLfk7F3EYVr1R'})\n",
    "test_down.GetContentFile('test.csv')\n",
    "sample_submission = drive.CreateFile({'id': '1NhBwCTwuARMBYX42IkpJxkLVxna8izrO'})\n",
    "sample_submission.GetContentFile('sample_submission.csv')\n",
    "new_merchant_transactions = drive.CreateFile({'id': '1j6h1qYKDITa7sLKbBIQqb63zCPEPZ1UY'})\n",
    "new_merchant_transactions.GetContentFile('new_merchant_transactions.csv')\n",
    "merchants = drive.CreateFile({'id': '1PBJFVu_xFxIPRh1cEw3x2fQf_xN-S3c0'})\n",
    "merchants.GetContentFile('merchants.csv')\n",
    "\n",
    "# THIS FILE IS VERY BIG ONLY DOWNLOAD IF NECESSARY\n",
    "# historical_transactions = drive.CreateFile({'id': '1FnqGiInHD6iCUAV_252NKriQysR4CNix'})\n",
    "# historical_transactions.GetContentFile('historical_transactions.csv')\n",
    "\n",
    "Data_Dictionary = drive.CreateFile({'id': '1_iodVkb84yU7ypEk26Xzld7mUDBCht7m'})\n",
    "Data_Dictionary.GetContentFile('Data_Dictionary.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lh7lws7IryUy"
   },
   "outputs": [],
   "source": [
    "# Loading files for training and testing\n",
    "\n",
    "# RMSE=3.925\n",
    "data = pd.read_csv('train_extra_features.csv')\n",
    "testdata = pd.read_csv('test_extra_features.csv')\n",
    "\n",
    "# RMSE=3.930\n",
    "# data = pd.read_csv('all/train.csv')\n",
    "# testdata = pd.read_csv('all/test.csv')\n",
    "\n",
    "# RMSE=3.948\n",
    "# Outliers removed and only the 3 given features\n",
    "# data = pd.read_csv('own_data/train_without_outliers.csv')\n",
    "# testdata = pd.read_csv('own_data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgc3XLzvryU1"
   },
   "source": [
    "## Training\n",
    "Training will be done in the following cells. First a random part of the training data is assigned as training set and the leftovers will be the validation set. By making the _trainsize_ variable round(train.shape[0]/1), the entirety of the training data is used as training set, so no evaluation will be done in the section _Testing within training set_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vliGFc7JryU2"
   },
   "outputs": [],
   "source": [
    "train = np.array(data)\n",
    "np.random.shuffle(train)\n",
    "trainsize = round(train.shape[0]/2) #fraction of trainingset used for training the model\n",
    "features = train.shape[1] - 3\n",
    "\n",
    "# A part of the training set can be used as a test set,\n",
    "# so the Root Mean Squared Error can be found\n",
    "train_l = train[:trainsize,features+2]\n",
    "train_x = train[:trainsize,2:features+2]\n",
    "\n",
    "test_l = train[trainsize:,features+2]\n",
    "test_x = train[trainsize:,2:features+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1696,
     "status": "ok",
     "timestamp": 1543954785220,
     "user": {
      "displayName": "Guido van der Heijden",
      "photoUrl": "https://lh3.googleusercontent.com/-Pgcdi2UCksE/AAAAAAAAAAI/AAAAAAAAABE/U-831Kz0YeQ/s64/photo.jpg",
      "userId": "00325871125681610562"
     },
     "user_tz": -60
    },
    "id": "ejp9v2gTryU5",
    "outputId": "da2cbbc7-1aba-486a-8530-18b97681ae5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               feature_1   feature_2   feature_3   fam_feature target      \n",
      "feature_1    [ 1.         -0.13096861  0.58309179 -0.11721539 -0.01425105]\n",
      "feature_2    [-0.13096861  1.          0.0609252  -0.15822695 -0.00624176]\n",
      "feature_3    [ 0.58309179  0.0609252   1.         -0.19610544 -0.00812528]\n",
      "fam_feature  [-0.11721539 -0.15822695 -0.19610544  1.          0.05046633]\n",
      "target       [-0.01425105 -0.00624176 -0.00812528  0.05046633  1.        ]\n"
     ]
    }
   ],
   "source": [
    "def CorrPrint(pandas_dataframe, numpy_array):\n",
    "    corr_matrix = np.corrcoef((train[:,2:numpy_array.shape[1]].T).astype(float))\n",
    "    \n",
    "    print(\" \"*15, sep=' ', end='', flush=True)\n",
    "    for i in range(numpy_array.shape[1]-2):\n",
    "        print(pandas_dataframe.columns[i+2], \" \"*(11 - len(pandas_dataframe.columns[i+2])), sep=' ', end='', flush=True)\n",
    "    print()\n",
    "    for i in range(numpy_array.shape[1]-2):\n",
    "        print(pandas_dataframe.columns[i+2], \" \"*(11 - len(pandas_dataframe.columns[i+2])), corr_matrix[i])\n",
    "    return\n",
    "\n",
    "CorrPrint(data,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bumqNdt1ryVC"
   },
   "outputs": [],
   "source": [
    "# Different regression models\n",
    "model_LR = LinearRegression().fit(train_x[:,3:5],train_l)\n",
    "\n",
    "# SVM took very long and didn't give better results\n",
    "# model_SVM = svm.SVR()\n",
    "# model_SVM.fit(train_x,train_l)\n",
    "\n",
    "model = model_LR # Selected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPwpvqAh9DG0"
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKI8ZkBiryVE"
   },
   "source": [
    "## Testing within training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ERl8rW4mryVG"
   },
   "outputs": [],
   "source": [
    "def RMSerror(y,y_pred):\n",
    "    if y.shape[0] != y_pred.shape[0]:\n",
    "        print(\"Root Mean Squared Error can't be calculated if number\" \\\n",
    "              \" of predictions isn't equal to number of labels!\")\n",
    "        return\n",
    "    \n",
    "    SE = 0\n",
    "    for i in range(y.shape[0]):\n",
    "        SE += np.square(y[i] - y_pred[i])\n",
    "    \n",
    "    RMSE = np.sqrt(SE / y.shape[0])\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1174,
     "status": "ok",
     "timestamp": 1543954786285,
     "user": {
      "displayName": "Guido van der Heijden",
      "photoUrl": "https://lh3.googleusercontent.com/-Pgcdi2UCksE/AAAAAAAAAAI/AAAAAAAAABE/U-831Kz0YeQ/s64/photo.jpg",
      "userId": "00325871125681610562"
     },
     "user_tz": -60
    },
    "id": "mpRoTvaaryVJ",
    "outputId": "17e66867-6e87-42be-992e-6cea01346133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8503222462124\n"
     ]
    }
   ],
   "source": [
    "if test_x.shape[0] > 0:\n",
    "    predictions = model.predict(test_x[:,3:5])\n",
    "    print(RMSerror(test_l,predictions))\n",
    "else:\n",
    "    print(\"No testing can be performed within the training set\" \\\n",
    "         \", because the entire training set is used for the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmGDIDfRryVN"
   },
   "source": [
    "## Predictions for test set (creating a submission .csv file)\n",
    "Make sure to use the entire training set in the the \"Training\" section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gazoBsGGryVO"
   },
   "outputs": [],
   "source": [
    "testset = np.array(testdata)\n",
    "\n",
    "testset_x = testset[:,2:features+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rl8acal1ryVR"
   },
   "outputs": [],
   "source": [
    "submission_predictions = model.predict(testset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJfiS7yCryVV",
    "outputId": "327cb600-0af0-4fbf-d907-4d274206303f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission was saved under the name:\u001b[1m submission_v0-004.csv\u001b[0;0m\n"
     ]
    }
   ],
   "source": [
    "# DOESNT WORK FOR DRIVE YET\n",
    "# submission.target = submission_predictions\n",
    "\n",
    "for i in range(1,100,1):\n",
    "    if os.path.isfile('submissions/submission_v0-00' + str(i) + '.csv') == False:\n",
    "        submission.to_csv('submissions/submission_v0-00' + str(i) + '.csv', index = False)\n",
    "        print('Submission was saved under the name:' + '\\033[1m' ' submission_v0-00' + str(i) + '.csv' + '\\033[0;0m')\n",
    "        break\n",
    "\n",
    "# [Errno 13] Permission denied: 'submissions/submission_v0-001.csv'\n",
    "#        means that the file is still opened somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i67lpOVFHo_4"
   },
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "drive_service = build('drive', 'v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOZ8PprDIGgt"
   },
   "outputs": [],
   "source": [
    "# Create a local file to upload.\n",
    "with open('/tmp/to_upload.txt', 'w') as f:\n",
    "  f.write(submission)\n",
    "\n",
    "print('/tmp/to_upload.txt contains:')\n",
    "!cat /tmp/to_upload.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5eTPD0ZFoTk"
   },
   "outputs": [],
   "source": [
    "# Upload the file to Drive. See:\n",
    "#\n",
    "# https://developers.google.com/drive/v3/reference/files/create\n",
    "# https://developers.google.com/drive/v3/web/manage-uploads\n",
    "file_metadata = {\n",
    "    'name': 'My Report',\n",
    "    'mimeType': 'application/vnd.google-apps.spreadsheet'\n",
    "}\n",
    "media = MediaFileUpload('files/report.csv',\n",
    "                        mimetype='text/csv',\n",
    "                        resumable=True)\n",
    "file = drive_service.files().create(body=file_metadata,\n",
    "                                    media_body=media,\n",
    "                                    fields='id').execute()\n",
    "print 'File ID: %s' % file.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 595,
     "status": "error",
     "timestamp": 1544714503281,
     "user": {
      "displayName": "Guido van der Heijden",
      "photoUrl": "https://lh3.googleusercontent.com/-Pgcdi2UCksE/AAAAAAAAAAI/AAAAAAAAABE/U-831Kz0YeQ/s64/photo.jpg",
      "userId": "00325871125681610562"
     },
     "user_tz": -60
    },
    "id": "qm7tq5FKJXX0",
    "outputId": "6ab0458c-430a-4e64-e3c7-4c8ade6556ec"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-15749b9a786b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'submission_v0-00'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_list5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: count() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "uploaded = drive.CreateFile({'title': 'submission_v0-00' + file_list5.count(0) })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1544714620474,
     "user": {
      "displayName": "Guido van der Heijden",
      "photoUrl": "https://lh3.googleusercontent.com/-Pgcdi2UCksE/AAAAAAAAAAI/AAAAAAAAABE/U-831Kz0YeQ/s64/photo.jpg",
      "userId": "00325871125681610562"
     },
     "user_tz": -60
    },
    "id": "HFW5GQl0KP55",
    "outputId": "ee777f6b-fbbb-43e2-c0ba-3ffc37173e87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list5.count(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40zkbINGryVZ"
   },
   "outputs": [],
   "source": [
    "# run this after previous cel to see the submission\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook Project - training and testing.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
